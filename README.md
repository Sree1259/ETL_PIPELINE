# Employee Data ETL Pipeline
## üìë Overview
This project demonstrates an end-to-end ETL pipeline for transforming and loading employee data into a PostgreSQL database for further analysis. It showcases Python fundamentals, data preprocessing, and version control best practices.

## üõ†Ô∏è Features & Capabilities
Extracts raw employee data from CSV files.

Cleans and prepares data:

Handles missing values.

Converts data types.

Applies consistent formatting.

Loads transformed data into PostgreSQL tables.

Generates log files for each pipeline execution.

### Separates concerns with modular scripts:

etl_pipeline.py: ETL orchestration.

utils.py: Helper functions.

db_connection.py: Database connectivity.

Maintains version control using Git.

## ‚öôÔ∏è Technologies Used
Python (loops, conditionals, OOP concepts)

Pandas for data manipulation

PostgreSQL as the target database

Git for version control and collaboration

## üìà Learning Outcomes
Explored Python basics and applied OOP principles in a real-world ETL workflow.

Built a reproducible ETL pipeline to process structured employee, project, and department data.

Developed logging to monitor pipeline executions.

Practiced clean code by modularizing scripts.

Conducted data validation and analysis within PostgreSQL.

Built a reproducible ETL pipeline to process structured employee, project, and department data.

Developed logging to monitor pipeline executions.

Practiced clean code by modularizing scripts and optimized for better readaility

Conducted data validation and analysis within PostgreSQL.
